# ğŸ¬ IMDb Sentiment Classification with Transformers

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/191eUE2hSgudijPSuD-NvCR23Ocznu5dj?usp=sharing)
[![W&B Report](https://img.shields.io/badge/Weights_&_Biases-View%20Report-orange?logo=weightsandbiases)]([YOUR_REPORT_LINK](https://api.wandb.ai/links/pulkiiit-infosys/d76a8m8m))

This project fine-tunes a pretrained Transformer (e.g., `distilbert-base-uncased`) on the IMDb movie reviews dataset to perform binary sentiment classification (positive or negative). It demonstrates transfer learning for NLP using the Hugging Face `transformers` library and PyTorch.

---

## ğŸš€ Features

- âœ… Fine-tunes a Transformer on the IMDb reviews dataset
- ğŸ§  Uses a custom PyTorch `Dataset` wrapper
- ğŸ” Automatic padding with `DataCollatorWithPadding`
- ğŸ“Š Tracks accuracy, precision, recall, and F1 score
- ğŸ“ˆ Plots training and validation loss
- ğŸ’¾ Saves the fine-tuned model and tokenizer

---

## ğŸ“š Dataset

- Source: [`keras.datasets.imdb`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb)
- 50,000 labeled movie reviews (25,000 train / 25,000 test)
- Binary sentiment labels: 0 (negative), 1 (positive)

---

## ğŸ§  Model & Training Details

- **Model**: `distilbert-base-uncased`
- **Tokenizer**: Hugging Face tokenizer with truncation and dynamic padding
- **Epochs**: 4
- **Batch Size**: 16
- **Max Sequence Length**: 512

---

## ğŸ§ª Evaluation Metrics

Achieved the following on the IMDb test set:

Accuracy : 93.02%
Precision : 93.03%
Recall : 93.01%
F1 Score : 93.02%

---
